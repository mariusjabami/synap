# ğŸ§  Synap â€“ Estudos de Redes Neurais em C++

<img src="img/icon1.jpg" alt="Neural Network Function" width="500"/>

---

## ğŸ“Œ Sobre

Este repositÃ³rio Ã© apenas um **registro dos meus estudos pessoais** em redes neurais.  
Aqui eu exploro como redes neurais funcionam internamente, escrevendo tudo do zero em C++ sem bibliotecas externas.  

ğŸ“– **Objetivo:** entender profundamente:
- Ajuste de pesos e bias
- Gradiente descendente aplicado manualmente
- DiferenÃ§a entre funÃ§Ãµes lineares e nÃ£o lineares
- Como equaÃ§Ãµes matemÃ¡ticas moldam o comportamento da rede

---

## âœï¸ FÃ³rmula do Modelo

O modelo que treinei possui:

- **2 pesos:** `w1`, `w2`  
- **1 viÃ©s (bias):** `b`  


ğŸ“Œ **Total de parÃ¢metros:** 3 (2 pesos + 1 bias)

Esse formato gera uma superfÃ­cie **nÃ£o linear** (parecida com um pano curvado em 3D), permitindo melhor ajuste dos dados.

---

## ğŸ¥ VÃ­deos Relacionados

ğŸ”¹ **Rodando e testando o modelo:**  
[![Testando](https://img.shields.io/badge/YouTube-Test-blue?logo=youtube)](https://youtube.com/shorts/7c5yteSsFDk?feature=share)

ğŸ”¹ **VisualizaÃ§Ã£o da fÃ³rmula e variaÃ§Ãµes nos parÃ¢metros:**  
[![FunÃ§Ã£o](https://img.shields.io/badge/YouTube-Function-blue?logo=youtube)](https://youtube.com/shorts/7PeUwnw10Vs?feature=share)

---

## ğŸ§  Conceitos Estudados

### ğŸ”¹ FunÃ§Ãµes Lineares vs NÃ£o Lineares
- **Linear:** saÃ­da Ã© uma reta ou plano  
  \[
  y = w \cdot x + b
  \]
- **NÃ£o Linear:** presenÃ§a de termos quadrÃ¡ticos, exponenciais, etc.  
  \[
  y = (x \cdot z)^2
  \]
- O modelo Ã© **nÃ£o linear**, conseguindo capturar relaÃ§Ãµes mais complexas.

### ğŸ”¹ FunÃ§Ã£o de Erro (Loss)
- Medida do quanto a previsÃ£o estÃ¡ distante do valor real.
- Quanto mais prÃ³ximo de **0**, melhor estÃ¡ o modelo.
- Aqui uso **erro quadrÃ¡tico mÃ©dio**.

### ğŸ”¹ Gradiente Descendente
- MÃ©todo para encontrar os melhores pesos ajustando-os gradualmente.
- Calcula-se a derivada da loss em relaÃ§Ã£o a cada parÃ¢metro e atualiza:
\[
w \gets w - \eta \frac{\partial \text{Loss}}{\partial w}
\]
onde `Î·` Ã© a **taxa de aprendizado**.

### ğŸ”¹ AtualizaÃ§Ã£o de Pesos e Bias
- Cada Ã©poca do treino recalcula gradientes
- Ajusta `w1`, `w2` e `b` atÃ© que a loss esteja muito baixa
- Esse processo "ensina" o modelo a se aproximar da funÃ§Ã£o original

---

## âš–ï¸ LicenÃ§a

Open Source â€“ vocÃª pode usar e modificar, mas **deixe os crÃ©ditos**.

---

ğŸ“Œ **Nota:** Este repositÃ³rio nÃ£o Ã© um framework ou projeto de produÃ§Ã£o. Ã‰ apenas parte da minha jornada aprendendo redes neurais na prÃ¡tica, escrevendo cÃ³digo e entendendo os fundamentos.